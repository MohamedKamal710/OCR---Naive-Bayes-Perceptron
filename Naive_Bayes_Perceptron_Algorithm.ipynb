{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26690884",
   "metadata": {},
   "source": [
    "### We declare a function that reads the files and seperate each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9aefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_images(filename_):\n",
    "    images = []\n",
    "    image = []\n",
    "    \n",
    "    file_ = open(filename_, \"r\")\n",
    "    row_number = 0  #counter to keep track number of rows (Every 28 rows = 1 image)\n",
    "    \n",
    "    for x in file_.readlines():\n",
    "        image.append(x[:28])\n",
    "        row_number+=1\n",
    "        if(row_number == 28):\n",
    "            images.append(image)\n",
    "            row_number = 0\n",
    "            image = []\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_labels(filename_):\n",
    "    labels = []\n",
    "    file_ = open(filename_)\n",
    "    for x in file_.readlines():\n",
    "        labels.append(int(x.strip()))\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63267171",
   "metadata": {},
   "source": [
    "### Read images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edffec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images_ = read_images('trainingimages')\n",
    "validation_images_ = read_images(\"validationimages\")\n",
    "test_images_ = read_images('testimages')\n",
    "\n",
    "training_labels = read_labels('traininglabels')\n",
    "validation_labels = read_labels(\"validationlabels\")\n",
    "test_labels = read_labels(\"testlabels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdff20d",
   "metadata": {},
   "source": [
    "# A - Naive Bayes Algorithm\n",
    "## (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d73b5e",
   "metadata": {},
   "source": [
    "### Build probability list for each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8849c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "total_num_images_of_digit = Counter(training_labels) ##Frequency of every digit\n",
    "\n",
    "def build_dict_pixels():\n",
    "    dict_pixels = {}\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            dict_pixels[str(i)+','+str(j)] = np.zeros(10) #Declare frequency array of size 10 for the digits\n",
    "    return dict_pixels\n",
    "\n",
    "pixels_black_prob = build_dict_pixels()\n",
    "\n",
    "for index, image in enumerate(training_images_): #For every black pixel increase the counter for the right digit(label)\n",
    "    for i , row in enumerate(image):\n",
    "        for j , col in enumerate(row):\n",
    "            if col == '#' or col == '+':\n",
    "                pixels_black_prob[str(i)+','+str(j)][training_labels[index]] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cbee21",
   "metadata": {},
   "source": [
    "### Calculate Probabilites for every image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91df9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "def cal_naive_bayes(image , k):\n",
    "    black_pixels = copy.deepcopy(pixels_black_prob)\n",
    "    \n",
    "    #Applying Laplace Smoothin with k value\n",
    "    for digits in black_pixels.values():\n",
    "        for index , value in enumerate(digits):\n",
    "            digits[index] = (value + k) / (total_num_images_of_digit[index] + (2*k))\n",
    "        \n",
    "    digits_prob = [0] * 10\n",
    "    for indexI , row in enumerate(image):\n",
    "        for indexJ , col in enumerate(row):\n",
    "            for i in range(10):\n",
    "                if col == '+' or col == '#':\n",
    "                    digits_prob[i] += math.log10(black_pixels[str(indexI)+','+str(indexJ)][i])\n",
    "                else:\n",
    "                    digits_prob[i] += math.log10( 1 - black_pixels[str(indexI)+','+str(indexJ)][i])\n",
    "\n",
    "\n",
    "    for index , digit in enumerate(digits_prob):\n",
    "        digits_prob[index] += math.log10(0.1)\n",
    "        \n",
    "    max_value = max(digits_prob)\n",
    "    return digits_prob.index(max_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1773438",
   "metadata": {},
   "source": [
    "### Function Classify  that apply cal_naive_bayes method on all images and return a list of predicted labels\n",
    "### We also declare a function get_accuracy to calculate the accuracy of our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d879e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify function: receives image dataset and k value for smoothing\n",
    "# We run through the images, for every image we use naive bayes classifier to predict the label\n",
    "# Returns the predicted labels\n",
    "def classify(image_list , k):\n",
    "    list_to_return = []\n",
    "    for image in image_list:\n",
    "        list_to_return.append(cal_naive_bayes(image , k))\n",
    "    return list_to_return\n",
    "\n",
    "\n",
    "# Check how many predicted labels were right predicted\n",
    "def get_accuracy(result_list , label_list):\n",
    "    counter = 0\n",
    "    for index , predicted in enumerate(result_list):\n",
    "        if predicted == label_list[index]:\n",
    "            counter+=1\n",
    "    \n",
    "    return counter / len(result_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eb72af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_data_k_1 = classify(validation_images_,1)\n",
    "validate_data_k_2 = classify(validation_images_,2)\n",
    "validate_data_k_3 = classify(validation_images_,3)\n",
    "validate_data_k_4 = classify(validation_images_,4)\n",
    "validate_data_k_5 = classify(validation_images_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b61e0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the classifier with Smoothing Value K=1 is: 0.818\n",
      "The accuracy of the classifier with Smoothing Value K=2 is: 0.819\n",
      "The accuracy of the classifier with Smoothing Value K=3 is: 0.812\n",
      "The accuracy of the classifier with Smoothing Value K=4 is: 0.811\n",
      "The accuracy of the classifier with Smoothing Value K=5 is: 0.81\n"
     ]
    }
   ],
   "source": [
    "def print_acc(accuracy,k):\n",
    "    print(\"The accuracy of the classifier with Smoothing Value K={} is: {}\".format(k,accuracy))\n",
    "    \n",
    "\n",
    "print_acc(get_accuracy(validate_data_k_1 , validation_labels) , 1)\n",
    "print_acc(get_accuracy(validate_data_k_2 , validation_labels) , 2)\n",
    "print_acc(get_accuracy(validate_data_k_3 , validation_labels), 3)\n",
    "print_acc(get_accuracy(validate_data_k_4 , validation_labels) , 4)\n",
    "print_acc(get_accuracy(validate_data_k_5 , validation_labels), 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067a486",
   "metadata": {},
   "source": [
    "#### For  k=2 we got  the highest accuracy, therefore we choose it to be our smoothing value for next sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2077c9",
   "metadata": {},
   "source": [
    "## (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27207466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy for test data is:  0.766\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "predict_test_data = classify(test_images_ , k )\n",
    "print(\"The prediction accuracy for test data is: \" , get_accuracy(predict_test_data , test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8039a1",
   "metadata": {},
   "source": [
    "## (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac1eedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy for training data is:  0.8378\n"
     ]
    }
   ],
   "source": [
    "predict_training_data = classify(training_images_ , k )\n",
    "print(\"The prediction accuracy for training data is: \" , get_accuracy(predict_training_data , training_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c3bdc",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "# B - Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d42aa0",
   "metadata": {},
   "source": [
    "### Convert all images to 0 and 1. ( 1 when pixel is # or + , 0 when empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c943142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert2d_to_1d(images):\n",
    "    images_to_return = []\n",
    "    for image in images:\n",
    "        images_to_return.append(image.flatten())\n",
    "    return images_to_return\n",
    "        \n",
    "def image_convertion(images):\n",
    "    for index , image in enumerate(images):\n",
    "        for i , row in enumerate(image):\n",
    "            for j , col in enumerate(row):\n",
    "                row = list(row)\n",
    "                if col == '#' or col == '+':\n",
    "                    row[j] = 1\n",
    "                else:\n",
    "                    row[j] = 0\n",
    "            image[i] = row\n",
    "        images[index] = np.array(image)\n",
    "    \n",
    "    return convert2d_to_1d(images)\n",
    "    \n",
    "    \n",
    "\n",
    "converted_training_images = image_convertion(training_images_)\n",
    "converted_tested_images = image_convertion(test_images_)\n",
    "converted_validation_images = image_convertion(validation_images_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa102c3e",
   "metadata": {},
   "source": [
    "### After converting all images to the right format, we now prepare the training dataset, we do that by:\n",
    "- For every digit (category) we run through all the training set and set 1 for every image that matches the label , 0 otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ffd727",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1 #Thats what is requested \n",
    "threshold = 0    #Since all weights are Integers that lay between INF and -INF we set threshold to be 0\n",
    "\n",
    "\n",
    "\n",
    "def prepare_training_dataset(training_set , label):\n",
    "    data = []\n",
    "    for index , pixels in enumerate(training_set):\n",
    "        fire = 0\n",
    "        if label == training_labels[index]:\n",
    "            fire = 1\n",
    "        image_and_label = (tuple(pixels) , fire )\n",
    "        data.append(image_and_label)\n",
    "    return data\n",
    "\n",
    "\n",
    "## We declare weights to be 0 (That what is requested in the question)\n",
    "#- We run in a loop of epochs range.\n",
    "#- for every tuple that consist of image (list of pixels) and a expected label:\n",
    "#  we calculate the dot product of weights vector and image pixels\n",
    "# if the result is above the threshold then we fire 1 and check if there is an error\n",
    "# if error exists , update weights with delta rule (OldWeight + Learning rate * (expected_label - result) * pixel_value[1,0])\n",
    "# Once we have reached max epochs , we return weights\n",
    "def perceptron_train(images , epochs):\n",
    "    weights = [0] * len(images[0][0])\n",
    "    for epoch in range(epochs):\n",
    "        err_count = 0\n",
    "        for pixel_vec , exp_label in images:\n",
    "            res = 0\n",
    "            if np.dot(pixel_vec , weights) > threshold:\n",
    "                res = 1\n",
    "            e = exp_label - res\n",
    "            if e != 0:\n",
    "                err_count+=1\n",
    "                for index , pixel_value in enumerate(pixel_vec):\n",
    "                    weights[index] += learning_rate * pixel_value * e\n",
    "\n",
    "    return weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f0a2a",
   "metadata": {},
   "source": [
    "## (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb333831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for digit: 0 is done.\n",
      "Training for digit: 1 is done.\n",
      "Training for digit: 2 is done.\n",
      "Training for digit: 3 is done.\n",
      "Training for digit: 4 is done.\n",
      "Training for digit: 5 is done.\n",
      "Training for digit: 6 is done.\n",
      "Training for digit: 7 is done.\n",
      "Training for digit: 8 is done.\n",
      "Training for digit: 9 is done.\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "digit_weights = dict.fromkeys(range(10) , [])\n",
    "\n",
    "for digit in digit_weights.keys():\n",
    "    digit_weights[digit] = perceptron_train(prepare_training_dataset(converted_training_images , digit),epochs)\n",
    "    print(\"Training for digit:\" , digit, 'is done.' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777bfc6d",
   "metadata": {},
   "source": [
    "### Lets examine how good our training was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d48453b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set with epochs set to 3 has reached:  0.8914\n",
      "Accuracy for test set has with epochs set to 3 reached:  0.793\n"
     ]
    }
   ],
   "source": [
    "#Classify Function: \n",
    "# it receives dataset of images and run through all the digits weights we have already calculated in training,\n",
    "# for every digit weight, get the score of the dot product and add it to a list of size 10 (digits)\n",
    "# for every image, return the label with the highest score\n",
    "def classify(data_images):\n",
    "    predicted_labels = []\n",
    "    for image in data_images:\n",
    "        max_score = []\n",
    "        for digit, weights in digit_weights.items():\n",
    "            score = np.dot(weights , image)\n",
    "            max_score.append(score)\n",
    "        predicted_labels.append(max_score.index(max(max_score)))\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "# Check how many predicted labels were right predicted\n",
    "def get_accuracy(predicted_labels , expected_labels):\n",
    "    counter = 0\n",
    "    for exp_label , pred_lab in zip(expected_labels,predicted_labels):\n",
    "        if exp_label == pred_lab:\n",
    "            counter+=1\n",
    "    return counter/len(expected_labels)\n",
    "\n",
    "\n",
    "\n",
    "train_acc = get_accuracy(classify(converted_training_images) , training_labels)\n",
    "print(\"Accuracy for training set with epochs set to 3 has reached: \", train_acc)\n",
    "test_acc = get_accuracy(classify(converted_tested_images) , test_labels)\n",
    "print(\"Accuracy for test set has with epochs set to 3 reached: \", test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03700902",
   "metadata": {},
   "source": [
    "## (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdc4d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_epochs(epochs):\n",
    "    for digit in digit_weights.keys():\n",
    "        digit_weights[digit] = perceptron_train(prepare_training_dataset(converted_training_images , digit),epochs)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff7170",
   "metadata": {},
   "source": [
    "### Epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6151e15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set with epochs set to 1 has reached:  0.8718\n",
      "Accuracy for test set has with epochs set to 1 reached:  0.804\n"
     ]
    }
   ],
   "source": [
    "train_with_epochs(epochs=1)\n",
    "train_acc = get_accuracy(classify(converted_training_images) , training_labels)\n",
    "print(\"Accuracy for training set with epochs set to 1 has reached: \", train_acc)\n",
    "test_acc = get_accuracy(classify(converted_tested_images) , test_labels)\n",
    "print(\"Accuracy for test set has with epochs set to 1 reached: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc65d7f2",
   "metadata": {},
   "source": [
    "### Epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9865c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set with epochs set to 2 has reached:  0.8902\n",
      "Accuracy for test set has with epochs set to 2 reached:  0.803\n"
     ]
    }
   ],
   "source": [
    "train_with_epochs(epochs=2)\n",
    "train_acc = get_accuracy(classify(converted_training_images) , training_labels)\n",
    "print(\"Accuracy for training set with epochs set to 2 has reached: \", train_acc)\n",
    "test_acc = get_accuracy(classify(converted_tested_images) , test_labels)\n",
    "print(\"Accuracy for test set has with epochs set to 2 reached: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275c181",
   "metadata": {},
   "source": [
    "### Epoch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77e2d652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set with epochs set to 4 has reached:  0.9008\n",
      "Accuracy for test set has with epochs set to 4 reached:  0.79\n"
     ]
    }
   ],
   "source": [
    "train_with_epochs(epochs=4)\n",
    "train_acc = get_accuracy(classify(converted_training_images) , training_labels)\n",
    "print(\"Accuracy for training set with epochs set to 4 has reached: \", train_acc)\n",
    "test_acc = get_accuracy(classify(converted_tested_images) , test_labels)\n",
    "print(\"Accuracy for test set has with epochs set to 4 reached: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513c3b5",
   "metadata": {},
   "source": [
    "### Epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd901cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set with epochs set to 5 has reached:  0.906\n",
      "Accuracy for test set has with epochs set to 5 reached:  0.796\n"
     ]
    }
   ],
   "source": [
    "train_with_epochs(epochs=5)\n",
    "train_acc = get_accuracy(classify(converted_training_images) , training_labels)\n",
    "print(\"Accuracy for training set with epochs set to 5 has reached: \", train_acc)\n",
    "test_acc = get_accuracy(classify(converted_tested_images) , test_labels)\n",
    "print(\"Accuracy for test set has with epochs set to 5 reached: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c04eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e72fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d213c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
